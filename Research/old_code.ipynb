{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "class DiscountType(Enum):\n",
    "    STANDARD = auto()\n",
    "    SEASONAL = auto()\n",
    "    WEIGHT = auto()\n",
    "\n",
    "def get_discounted_price(cart_weight, total_price, discount_type):\n",
    "    if discount_type == DiscountType.STANDARD:\n",
    "        total_price = total_price - total_price * 0.06\n",
    "        \n",
    "    elif discount_type == DiscountType.SEASONAL:\n",
    "        total_price = total_price - total_price * 0.12\n",
    "        \n",
    "    elif discount_type == DiscountType.WEIGHT:\n",
    "        if cart_weight <= 10:\n",
    "            total_price = total_price - total_price * 0.06\n",
    "        else:\n",
    "            total_price = total_price - total_price * 0.18\n",
    "    \n",
    "    return total_price\n",
    "\n",
    "print(get_discounted_price(12, 100, DiscountType.SEASONAL))\n",
    "\n",
    "\n",
    "\n",
    "def group_by_owners(files):\n",
    "    owner_list=[]\n",
    "    print(files)\n",
    "    for file,owner in files.items():\n",
    "        \n",
    "        #print(owner)\n",
    "        if owner in owner_list:\n",
    "            owner_list.append(file)\n",
    "        else:\n",
    "            owner_list(owner)\n",
    "    return owner_list\n",
    "def group_by_owners(files):\n",
    "    owners_dict = {}  # Dictionary to store owners and their corresponding files\n",
    "\n",
    "    for file, owner in files.items():\n",
    "        \n",
    "        if owner in owners_dict:\n",
    "            owners_dict[owner].append(file)\n",
    "        else:\n",
    "            owners_dict[owner] = [file]\n",
    "\n",
    "    return owners_dict\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    files = {\n",
    "        'Input.txt': 'Randy',\n",
    "        'Code.py': 'Stan',\n",
    "        'Output.txt': 'Randy'\n",
    "    }   \n",
    "    print(group_by_owners(files))\n",
    "\n",
    "\n",
    "\n",
    "    function GraphChallenge(strArr) {\n",
    "    // Convert strArr into an adjacency list\n",
    "    const graph = {};\n",
    "    strArr.forEach(edge => {\n",
    "        const [node1, node2] = edge.split('-');\n",
    "        if (!graph[node1]) graph[node1] = [];\n",
    "        if (!graph[node2]) graph[node2] = [];\n",
    "        graph[node1].push(node2);\n",
    "        graph[node2].push(node1);\n",
    "    });\n",
    "\n",
    "    // Function to perform DFS and find the longest path\n",
    "    function dfs(node, visited, pathLength) {\n",
    "        visited.add(node);\n",
    "        let maxLength = pathLength;\n",
    "\n",
    "        for (const neighbor of graph[node]) {\n",
    "            if (!visited.has(neighbor)) {\n",
    "                const length = dfs(neighbor, visited, pathLength + 1);\n",
    "                maxLength = Math.max(maxLength, length);\n",
    "            }\n",
    "        }\n",
    "        visited.delete(node); // Allow re-visit of nodes in different paths\n",
    "        return maxLength;\n",
    "    }\n",
    "\n",
    "    // __define-ocg__ Define the initial values for the DFS traversal\n",
    "    let maxPathLength = 0;\n",
    "    const visited = new Set();\n",
    "\n",
    "    // Try to start DFS from each node to ensure we cover all connected components\n",
    "    for (const node in graph) {\n",
    "        maxPathLength = Math.max(maxPathLength, dfs(node, visited, 0));\n",
    "    }\n",
    "\n",
    "    return maxPathLength;\n",
    "}\n",
    "\n",
    "// Test cases\n",
    "console.log(GraphChallenge([\"b-e\",\"b-c\",\"c-d\",\"a-b\",\"e-f\"])); // Output: 4\n",
    "console.log(GraphChallenge([\"b-a\",\"c-e\",\"b-c\",\"d-c\"]));     // Output: 3\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming your DataFrame 'df' is already loaded with 352 rows and 50 columns\n",
    "# For this example, we'll create a dummy DataFrame\n",
    "df = pd.DataFrame(np.random.rand(352, 50))  # Replace this with your actual DataFrame\n",
    "\n",
    "# Splitting the data into training and testing sets (80% training, 20% testing)\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data = df.iloc[:train_size]\n",
    "test_data = df.iloc[train_size:]\n",
    "\n",
    "# Separate the features and target variable\n",
    "x_train = train_data.iloc[:, :-1].values  # All columns except the last one\n",
    "y_train = train_data.iloc[:, -1].values   # Last column as target\n",
    "x_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "# Reshape x_train and x_test to be 3D [samples, timesteps, features] as required by LSTM\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))  # (samples, timesteps, features)\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Build the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer to define input shape\n",
    "model.add(Input(shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "# First LSTM layer with Dropout\n",
    "model.add(LSTM(units=4, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Second LSTM layer with Dropout\n",
    "model.add(LSTM(units=4))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense layer to output a single value (the predicted stock price)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=16, verbose=0)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Print the last column of the prediction array\n",
    "print(y_pred[:, -1])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
